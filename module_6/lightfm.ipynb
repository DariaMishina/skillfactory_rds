{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки и загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Для визуализации\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#вывод максимального количества строк и столбцов\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "#Для моделирования\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробовала 2мя способами удалить дубликаты в обучающей выборке, в итоге это только ухудшило результат на kaggle приблизительно до 0.73. В итоге ничего не удаляла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.drop_duplicates().reset_index(drop = True)\n",
    "#train.drop_duplicates(subset=['userid', 'itemid'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строим разреженную матрицу взаимодействия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже модель из бэйзлайна, с подобранными руками гиперпараметрами, результат на kaggle 0.75125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем на обучающую и тестовую выборки\n",
    "train_data, test_data = train_test_split(train,random_state=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем спарс матрицу - то есть, разреженную матрицу, нули в которой не хранятся\n",
    "ratings_coo = sparse.coo_matrix((train_data['rating'].astype(int),\n",
    "                                 (train_data['userid'],\n",
    "                                  train_data['itemid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выводим часть гиперпараметров отдельно\n",
    "NUM_THREADS = 4 #число потоков\n",
    "NUM_COMPONENTS = 55 #число параметров вектора \n",
    "NUM_EPOCHS = 15 #число эпох обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определяем модель\n",
    "model_t = LightFM(learning_rate=0.115, loss='logistic',\n",
    "                no_components=NUM_COMPONENTS, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучаем модель\n",
    "model_t = model_t.fit(ratings_coo, epochs=NUM_EPOCHS, num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#предсказываем рейтинг на тестовой выборке\n",
    "preds = model_t.predict(test_data.userid.values,\n",
    "                      test_data.itemid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517362831861725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#считаем roc_auc\n",
    "sklearn.metrics.roc_auc_score(test_data.rating,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считаем рейтинг\n",
    "preds = model_t.predict(test.userid.values,\n",
    "                      test.itemid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-24.29817008972168, 24.720426559448242)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#оцениваем минимальное и максимальное значение\n",
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#нормируем значения рейтинга\n",
    "normalized_preds = (preds - preds.min())/(preds - preds.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверяем, что получилось\n",
    "normalized_preds.min(), normalized_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выгружаем результат для сабмишна\n",
    "submission['rating']= normalized_preds\n",
    "submission.to_csv('submission_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы использовать метрики precision и recall из библиотеки lightfm, надо сначала сделать спарс матрицу (разреженную) для всего датасета train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_coo = sparse.coo_matrix((train['rating'].astype(int),\n",
    "                                 (train['userid'],\n",
    "                                  train['itemid']))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#с помощью random_train_test_split из LightFM сделать разбивку на тест и трейн\n",
    "train_coo, test_coo = random_train_test_split(ratings_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выводим часть гиперпараметров отдельно\n",
    "NUM_THREADS = 4 #число потоков\n",
    "NUM_COMPONENTS = 55 #число параметров вектора \n",
    "NUM_EPOCHS = 15 #число эпох обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определяем модель\n",
    "model = LightFM(learning_rate=0.115, loss='logistic', no_components=NUM_COMPONENTS,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучаем модель\n",
    "model = model.fit(train_coo, epochs=NUM_EPOCHS, \n",
    "                  num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Сделаем предсказание на тестовой выборке\n",
    "preds = model.predict(test_coo.row,\n",
    "                      test_coo.col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7564548187843096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на метрику roc_auc_score\n",
    "sklearn.metrics.roc_auc_score(test_coo.data,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0, 0.7022203)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на метрику из LighfFM:\n",
    "auc_LFM = auc_score(model=model, test_interactions=test_coo)\n",
    "auc_LFM.max(), auc_LFM.min(), auc_LFM.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "метрики roc_auc из sklearn и lightfm существенно отличаются, посмотрим какой результат будет на kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.020512936636805534, recall: 0.061677793206188894\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем precision, recall.\n",
    "pr_at_k = precision_at_k(model=model, test_interactions=test_coo, k=5)\n",
    "rc_at_k = recall_at_k(model=model, test_interactions=test_coo, k=5)\n",
    "print(f'Precision: {pr_at_k.mean()}, recall: {rc_at_k.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считаем рейтинг\n",
    "preds = model.predict(test.userid.values,\n",
    "                      test.itemid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-24.599472045898438, 30.27789878845215)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#оцениваем минимальное и максимальное значение\n",
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#нормируем значения рейтинга\n",
    "normalized_preds = (preds - preds.min())/(preds - preds.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверяем, что получилось\n",
    "normalized_preds.min(), normalized_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выгружаем результат для сабмишна\n",
    "submission['rating']= normalized_preds\n",
    "submission.to_csv('submission_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "результат на kaggle оказался гораздо лучше, чем при первом подходе, гиперпараметры остались неизменными 0.75604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендации для пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для существующих пользователей дадим рекомендации на основании их покупок, а новым пользователям предложим наиболее популярные товары"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получим эмбеддинги и запишем их в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6982001, 3.1139927)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сохранение векторных представлений айтемов для дальнейшего деплоя в продакшн\n",
    "#item_biases, item_embeddings = model.get_item_representations(features=item_features)\n",
    "item_biases, item_embeddings = model.get_item_representations()\n",
    "user_biases, user_embeddings = model.get_user_representations()\n",
    "user_embeddings.max(), item_embeddings.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nmslib\n",
      "  Downloading nmslib-2.0.6-cp37-cp37m-manylinux2010_x86_64.whl (13.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.0 MB 2.0 MB/s eta 0:00:01    |██▎                             | 942 kB 883 kB/s eta 0:00:14                         | 1.6 MB 883 kB/s eta 0:00:13     |██████▋                         | 2.7 MB 883 kB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from nmslib) (5.7.0)\n",
      "Requirement already satisfied: pybind11>=2.2.3 in /opt/conda/lib/python3.7/site-packages (from nmslib) (2.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from nmslib) (1.18.1)\n",
      "Installing collected packages: nmslib\n",
      "Successfully installed nmslib-2.0.6\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    " \n",
    "#Создаём граф для поиска\n",
    "nms_idx = nmslib.init(method='hnsw', space='cosinesimil')\n",
    " \n",
    "#Добавляем товары в граф\n",
    "nms_idx.addDataPointBatch(item_embeddings)\n",
    "nms_idx.createIndex(print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вспомогательная функция для поиска по графу\n",
    "def nearest_item_nms(item_id, index, n=5):\n",
    "    nn = index.knnQuery(item_embeddings[item_id], k=n)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним эмбеддинги для прототипа\n",
    "import pickle\n",
    "with open('item_embeddings.pickle', 'wb') as file:\n",
    "    pickle.dump(item_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "очень долго считалось, ушло все время GPU, в бэкграунде - save and run all запускала, так же не посчиталось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    try:\n",
    "        \n",
    "        print(params) #добавила вывод параметров на печать\n",
    "    # unpack\n",
    "        epochs, learning_rate,\\\n",
    "        no_components, alpha = params\n",
    "    \n",
    "        user_alpha = alpha\n",
    "        item_alpha = alpha\n",
    "        model = LightFM(loss='logistic',#пробовала warp\n",
    "                        random_state=32,\n",
    "                        learning_rate=learning_rate,\n",
    "                        no_components=no_components,\n",
    "                        user_alpha=user_alpha,\n",
    "                        item_alpha=item_alpha)\n",
    "        model.fit(train_coo, epochs=epochs,#вот тут train_coo \n",
    "                  num_threads=4,verbose=True) \n",
    "    #есть смысл переделать для roc_auc так как в задании он\n",
    "        patks = precision_at_k(model, test_coo,#вот тут подставила test_coo\n",
    "                                                  train_interactions=None,\n",
    "                                                  k=5, num_threads=4)\n",
    "        mapatk = np.mean(patks)\n",
    "    # меняем знак на минус, так как нам надо минимизировать\n",
    "        out = -mapatk\n",
    "    # откопала в статье,н=здесь ни на что не влияет, но пусть будет\n",
    "        if np.abs(out + 1) < 0.01 or out < -1.0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return out\n",
    "        \n",
    "    except ValueError as err: #все время лезла ошибка с таким типом из-за слишком маленьких значений, добавила try except, чтобы считалось\n",
    "        print(err)\n",
    "        return 9999.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [(1, 260), # epochs \n",
    "         (10**-4, 10**-1, 'log-uniform'), # learning_rate \n",
    "         (20, 200), # no_components \n",
    "         (10**-6, 10**-1, 'log-uniform'), # alpha \n",
    "        ]\n",
    "\n",
    "res_fm = forest_minimize(objective, space, n_calls=250,\n",
    "                     random_state=0, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximimum p@k found: {:6.5f}'.format(-res_fm.fun))\n",
    "print('Optimal parameters:')\n",
    "params = ['epochs', 'learning_rate', 'no_components', 'alpha']\n",
    "for (p, x_) in zip(params, res_fm.x):\n",
    "    print('{}: {}'.format(p, x_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c optuna пока не все получилось, [нашла статью](https://www.eigentheories.com/blog/lightfm-vs-hybridsvd/) но метод fit_params устарел, а аналогов не нашла пока, буду разбираться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: cliff in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (3.4.0)\n",
      "Requirement already satisfied: cmaes>=0.6.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (0.6.1)\n",
      "Requirement already satisfied: colorlog in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (4.2.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (1.3.13)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (20.1)\n",
      "Requirement already satisfied: alembic in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (1.4.3)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: numpy in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (1.18.1)\n",
      "Requirement already satisfied: tqdm in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (4.42.1)\n",
      "Requirement already satisfied: joblib in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from optuna) (0.14.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (5.5.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (3.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (1.14.0)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (1.3.10)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (5.3)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cliff->optuna) (2.4.6)\n",
      "Requirement already satisfied: Mako in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from alembic->optuna) (1.1.3)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from stevedore>=2.0.1->cliff->optuna) (2.0.0)\n",
      "Requirement already satisfied: setuptools>=34.4 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (46.0.0.post20200309)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.1.8)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dariamishina/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "try: # import lightweight progressbar\n",
    "    from ipypb import track\n",
    "except ImportError: # fallback to default\n",
    "    from tqdm.auto import tqdm as track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lightfm(model):\n",
    "    '''Convenience function for evaluating LightFM.\n",
    "    It disables user bias terms to improve quality in cold start.'''\n",
    "    model._model.user_biases *= 0.0\n",
    "    return model.evaluate()\n",
    "\n",
    "def find_target_metric(metrics, target_metric):\n",
    "    'Convenience function to quickly extract the required metric.'\n",
    "    for metric in metrics:\n",
    "        if hasattr(metric, target_metric):\n",
    "            return getattr(metric, target_metric)\n",
    "\n",
    "def lightfm_objective(model, target_metric):\n",
    "    'Objective function factory for optuna trials.'\n",
    "    def objective(trial):\n",
    "        # sample hyper-parameter values\n",
    "        model.rank = trial.suggest_int('rank', 1, max_rank)\n",
    "        model.item_alpha = trial.suggest_loguniform('item_alpha', 1e-10, 1e-0)\n",
    "        # train model silently and evaluate\n",
    "        model.verbose = False\n",
    "        model.build()\n",
    "        metrics = evaluate_lightfm(model)\n",
    "        target = find_target_metric(metrics, target_metric)\n",
    "        # store trial-specific information for later use\n",
    "        trial.set_user_attr('epochs', model.fit_params['epochs'])\n",
    "        #fit(X, y=None, *, groups=None, **fit_params)\n",
    "        trial.set_user_attr('metrics', metrics)\n",
    "        return target\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = {\n",
    "# epochs: # trials\n",
    "    15: 30,\n",
    "    25: 25,\n",
    "    50: 20,\n",
    "    75: 15,\n",
    "    100: 10,\n",
    "    150: 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metric = 'precision'\n",
    "objective = lightfm_objective(model, target_metric)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction = 'maximize',\n",
    "    sampler = optuna.samplers.TPESampler(seed=32)\n",
    ")\n",
    "\n",
    "optuna.logging.disable_default_handler() # do not report progress\n",
    "for num_epochs, num_trials in track(n_trials.items()):\n",
    "    model.fit_params['epochs'] = num_epochs\n",
    "    study.optimize(objective, n_trials=num_trials, n_jobs=1, catch=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f'The best value of {target_metric}={study.best_value:0.4f} was achieved with '\n",
    "      f'rank={study.best_params[\"rank\"]} and item_alpha={study.best_params[\"item_alpha\"]:.02e} '\n",
    "      f'within {study.best_trial.user_attrs[\"epochs\"]} epochs.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
